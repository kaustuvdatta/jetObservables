{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5233b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7586a4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#from keras import backend as K\n",
    "\n",
    "import pylab\n",
    "import random\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import copy\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "sys.path.insert(0,'../python/')\n",
    "from NN_helpers_keras import *\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,callbacks,models,optimizers,layers,initializers,regularizers,constraints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b87049",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be83b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.RandomState(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a01e47",
   "metadata": {},
   "source": [
    "## W vs QCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f64cacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpDir='../data/'\n",
    "cols=dict()\n",
    "hidden_size1=500\n",
    "hidden_size2=250\n",
    "hidden_size3=100\n",
    "hidden_size4=50\n",
    "batch_size = 5000\n",
    "epochs = 400\n",
    "cmap = get_cmap(30)\n",
    "\n",
    "#branch ordering\n",
    "#0'selGenJets_nom_pt', 1'selGenJets_nom_msoftdrop',  \n",
    "#2'selGenJets_nom_tau_0p5_1', 3'selGenJets_nom_tau_1_1', 4'selGenJets_nom_tau_2_1',\n",
    "#5'selGenJets_nom_tau_0p5_2', 6'selGenJets_nom_tau_1_2', 7'selGenJets_nom_tau_2_2',\n",
    "#8'selGenJets_nom_tau_0p5_3', 9'selGenJets_nom_tau_1_3', 10'selGenJets_nom_tau_2_3',\n",
    "#11'selGenJets_nom_tau_0p5_4', 12'selGenJets_nom_tau_1_4', 13'selGenJets_nom_tau_2_4', \n",
    "#14'selGenJets_nom_tau_0p5_5', 15'selGenJets_nom_tau_1_5', 16'selGenJets_nom_tau_2_5',\n",
    "#17'selGenJets_nom_tau21', 18'selGenJets_nom_tau32', \n",
    "#19'selGenJets_nom_tau21_WTA',20'selGenJets_nom_tau32_WTA', \n",
    "#21'selGenJets_nom_tau21_exkT',22'selGenJets_nom_tau32_exkT', \n",
    "cols['2-body'] = [3,4]\n",
    "cols['3-body'] = [2,3,4,6,7]\n",
    "cols['4-body'] = [2,3,4,5,6,7,9,10]\n",
    "cols['5-body'] = [2,3,4,5,6,7,8,9,10,12,13]\n",
    "cols['6-body'] = [2,3,4,5,6,7,8,9,10,11,12,13,15,16]\n",
    "cols['tau21'] = [17]\n",
    "cols['tau32'] = [18]\n",
    "cols['tau21_WTA'] = [19]\n",
    "cols['tau32_WTA'] = [20]\n",
    "cols['tau21_exkT'] = [21]\n",
    "cols['tau32_exkT'] = [22]\n",
    "\n",
    "Ms = [2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a13d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from collections import OrderedDict\n",
    "genDictScoreNN = OrderedDict()\n",
    "genDictScoreObs = OrderedDict()\n",
    "recoDictScoreNN = OrderedDict()\n",
    "recoDictScoreObs = OrderedDict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16371853",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad12ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "for sampleType in ['Wlike']:#,'toplike']:\n",
    "    for genORreco in ['gen','reco']:#,'reco']\n",
    "        print(sampleType,genORreco)\n",
    "        for f in os.listdir(inpDir):\n",
    "\n",
    "            if not(sampleType in f and genORreco in f): continue\n",
    "            print (f,genORreco)\n",
    "            file = h5py.File(inpDir+f,'r')\n",
    "\n",
    "            inputs = np.array(file['inputs']).reshape(file['inputs'].shape[1],file['inputs'].shape[2])\n",
    "            targets = np.array(file['target']).flatten()#reshape(targets.shape[1])\n",
    "            #print(inputs.shape[0],targets[0:100])\n",
    "            dataset_dict = split_data(inputs,targets)\n",
    "            file.close()\n",
    "        \n",
    "        print(f\"Train set shape: Inputs {dataset_dict['inputs']['train'].shape}, Target {dataset_dict['targets']['train'].shape}\")\n",
    "        print(f\"Validate set shape: Inputs {dataset_dict['inputs']['validate'].shape}, Target {dataset_dict['targets']['validate'].shape}\")\n",
    "        print(f\"Test set shape: Inputs {dataset_dict['inputs']['test'].shape}, Target {dataset_dict['targets']['test'].shape}\")\n",
    "\n",
    "        ### M-body DNN training for W/top vs. QCD ###\n",
    "        inputs_train = dataset_dict['inputs']['train']\n",
    "        inputs_val = dataset_dict['inputs']['validate']\n",
    "        inputs_test = dataset_dict['inputs']['test']\n",
    "        target_train = dataset_dict['targets']['train']\n",
    "        target_val = dataset_dict['targets']['validate']\n",
    "        target_test = dataset_dict['targets']['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bee268d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sampleType in ['Wlike']:#,'toplike']:\n",
    "    for genORreco in ['gen','reco']:#,'reco']\n",
    "        print(sampleType,genORreco)\n",
    "        \n",
    "        for M in Ms:\n",
    "            plt.figure(figsize=(12, 9))\n",
    "\n",
    "            input_shape=(len(cols[f'{M}-body']),)\n",
    "            for i in range(1,10):\n",
    "                DNN_WvsQCD_Mbody = keras.Sequential([\n",
    "                        layers.Dense(hidden_size1, activation='relu', input_shape=input_shape),\n",
    "                        layers.Dropout(0.2),\n",
    "                        layers.Dense(hidden_size2, activation='relu'),\n",
    "                        layers.Dropout(0.2),\n",
    "                        layers.Dense(hidden_size3, activation='relu'),\n",
    "                        layers.Dropout(0.1),\n",
    "                        layers.Dense(hidden_size4, activation='relu'),\n",
    "                        layers.Dropout(0.1),\n",
    "                        layers.Dense(1, activation='sigmoid')\n",
    "                    ])\n",
    "                DNN_WvsQCD_Mbody.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "                #DNN_WvsQCD_Mbody.summary()\n",
    "                modelname = f\"{genORreco}_DNN_WvsQCD_{M}body_{i}\"   \n",
    "                #print (f\"Training {modelname}\")\n",
    "                check = keras.callbacks.ModelCheckpoint(filepath=f\"../saved_weightsAndES/{modelname}_check.h5\", verbose=0)\n",
    "                early = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto')\n",
    "                history = DNN_WvsQCD_Mbody.fit(  \n",
    "                                                inputs_train[:,cols[f'{M}-body']], target_train, \n",
    "                                                batch_size=batch_size, epochs=epochs, \n",
    "                                                steps_per_epoch=5,\n",
    "                                                validation_data=(inputs_val[:,cols[f'{M}-body']], target_val),\n",
    "                                                validation_batch_size=int(batch_size/2), validation_steps=4, \n",
    "                                                verbose=0, callbacks=[check, early]\n",
    "                                               )\n",
    "                savelosses(history,outDir='../saved_weightsAndES/',name=modelname)\n",
    "                savemodel(DNN_WvsQCD_Mbody,outDir='../models/',name=modelname)\n",
    "\n",
    "                plt.plot(history.history['loss'], color=cmap(i), label=(f\"{i}_loss\"))\n",
    "                plt.plot(history.history['val_loss'], linestyle=\"--\", color=cmap(i))    \n",
    "\n",
    "                pred = DNN_WvsQCD_Mbody.predict([inputs_test[:,cols[f'{M}-body']]])\n",
    "                fpr,tpr,_ = roc_curve(target_test,pred)\n",
    "                ls = ['-' , '--' , '-.']\n",
    "                area = auc(fpr, tpr)\n",
    "                if area>score[0]:\n",
    "                    score[0]=area\n",
    "                    score[1]=i\n",
    "                if area<=0.6:\n",
    "                    continue\n",
    "                l = 'Training %d, auc=%f'%(i,area)\n",
    "                print(l,modelname,score)\n",
    "                del(DNN_WvsQCD_Mbody)\n",
    "                gc.collect()\n",
    "\n",
    "            #plt.yscale('log')\n",
    "            plt.xlabel('Epoch', fontsize = 20)\n",
    "            plt.ylabel('Loss', fontsize = 20)\n",
    "            plt.title('Training Error by Epoch', fontsize = 20)    \n",
    "            plt.legend(loc='best', fontsize = 15, fancybox=True, framealpha=0.0)\n",
    "            plt.rc('xtick', labelsize = 16)\n",
    "            plt.rc('ytick', labelsize = 16)   \n",
    "            plt.savefig(f\"../Plots/{genORreco}_DNN_WvsQCD_{M}body_losses.pdf\")\n",
    "            plt.savefig(f\"../Plots/{genORreco}_DNN_WvsQCD_{M}body_losses.png\")\n",
    "            plt.show()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e3b10f",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb85cec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "genDictScoreNN=dict()\n",
    "recoDictScoreNN=dict()\n",
    "genDictScoreObs=dict()\n",
    "recoDictScoreObs=dict()\n",
    "gc.collect()\n",
    "\n",
    "problem = ['WvsQCD']#,'topvsQCD']\n",
    "for p in problem:#,'toplike']:\n",
    "    for genORreco in ['gen','reco']:\n",
    "        for obs in cols.keys():\n",
    "            if not('tau' in obs):\n",
    "                genDictScoreNN[f'{obs}_DNN_{p}']=dict()\n",
    "                recoDictScoreNN[f'{obs}_DNN_{p}']=dict()\n",
    "            else:  \n",
    "                if('32' in obs and 'W' in p): continue \n",
    "                if('21' in obs and 'top' in p): continue \n",
    "                genDictScoreObs[f'{obs}_{p}']=dict()\n",
    "                recoDictScoreObs[f'{obs}_{p}']=dict()\n",
    "            print(p,genORreco,obs)\n",
    "\n",
    "print(genDictScoreNN,recoDictScoreNN,genDictScoreObs,recoDictScoreObs)\n",
    "\n",
    "for p in problem:#,'toplike']:\n",
    "    for genORreco in ['gen','reco']:\n",
    "        for obs in cols.keys():\n",
    "            print(obs,genORreco,p)\n",
    "            #print(sampleType,genORreco)\n",
    "            \n",
    "            if not('tau' in obs):\n",
    "                \n",
    "                best_score=[0,0]\n",
    "                for i in range(1,10):\n",
    "                    \n",
    "                    modelname=f'{genORreco}_DNN_{p}_{obs.split(\"-\")[0]}body_{i}'\n",
    "                    model = loadmodel(modelname,inDir='../models/')\n",
    "                    prediction = np.array(model.predict(np.array(inputs_test[:,cols[obs]]),verbose=0))\n",
    "                    fpr, tpr, _ = roc_curve(np.array(target_test),prediction)\n",
    "                    area = auc(fpr,tpr)\n",
    "                    \n",
    "                    if area>best_score[0]:\n",
    "                        \n",
    "                        best_score[0]=area\n",
    "                        best_score[1]=i\n",
    "                        if 'gen' in genORreco:\n",
    "                            genDictScoreNN[f'{obs}_DNN_{p}']['fpr'] = fpr\n",
    "                            genDictScoreNN[f'{obs}_DNN_{p}']['tpr'] = tpr\n",
    "                            genDictScoreNN[f'{obs}_DNN_{p}']['AUC'] = np.round(area,3)\n",
    "                            genDictScoreNN[f'{obs}_DNN_{p}']['model'] = modelname\n",
    "                        elif 'reco' in genORreco:\n",
    "                            recoDictScoreNN[f'{obs}_DNN_{p}']['fpr'] = fpr\n",
    "                            recoDictScoreNN[f'{obs}_DNN_{p}']['tpr'] = tpr\n",
    "                            recoDictScoreNN[f'{obs}_DNN_{p}']['AUC'] = np.round(area,3)\n",
    "                            recoDictScoreNN[f'{obs}_DNN_{p}']['model'] = modelname\n",
    "                            \n",
    "                        #print(obs,modelname,genDictScoreNN,recoDictScoreNN)\n",
    "\n",
    "                    elif area<=0.6:\n",
    "                        continue\n",
    "            elif ('tau' in obs):\n",
    "                if('32' in obs and 'W' in p): continue \n",
    "                if('21' in obs and 'top' in p): continue \n",
    "                \n",
    "                inds_0 = np.where(target_test==0)\n",
    "                inds_1 = np.where(target_test==1)\n",
    "                print (len(inds_0),len(inds_1))\n",
    "                fpr,tpr,area = makeROC_obs(sig=inputs_test[:,cols[obs]][inds_1],\n",
    "                                           bkg=inputs_test[:,cols[obs]][inds_0])\n",
    "                if 'gen' in genORreco:\n",
    "                    genDictScoreObs[f'{obs}_{p}']['fpr'] = fpr\n",
    "                    genDictScoreObs[f'{obs}_{p}']['tpr'] = tpr\n",
    "                    genDictScoreObs[f'{obs}_{p}']['AUC'] = np.round(area,3)\n",
    "                elif 'reco' in genORreco:\n",
    "                    recoDictScoreObs[f'{obs}_{p}']['fpr'] = fpr\n",
    "                    recoDictScoreObs[f'{obs}_{p}']['tpr'] = tpr\n",
    "                    recoDictScoreObs[f'{obs}_{p}']['AUC'] = np.round(area,3)\n",
    "                    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c9adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(genDictScoreNN)\n",
    "print(genDictScoreObs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9623ee3",
   "metadata": {},
   "source": [
    "### Make saturation ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5002a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mplhep as hep\n",
    "import matplotlib.pyplot as plt\n",
    "hep.style.use(\"CMS\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c2c41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,9))\n",
    "\n",
    "#gen level\n",
    "for i in genDictScoreNN.keys():\n",
    "    plt.plot(genDictScoreNN[i]['tpr'],1./genDictScoreNN[i]['fpr'], label=i.split('_DNN')[0]+f' DNN (AUC={genDictScoreNN[i][\"AUC\"]})',\n",
    "             ls='-', lw=2)\n",
    "for i in genDictScoreObs.keys():\n",
    "    print(i)\n",
    "    if 'ex' in i: lab=r'$\\%s_{21}^{%s}$'%(i.split('21')[0],r'excl.\\ k_{T}')\n",
    "    elif 'WTA' in i: lab=r'$\\%s_{21}^{%s}$'%(i.split('21')[0],r'WTA\\ k_{T}')\n",
    "    elif i=='tau21_WvsQCD': lab=r'$\\%s_{21}^{%s}$'%(i.split('21')[0],r'OP\\ k_{T}' )\n",
    "    plt.plot(genDictScoreObs[i]['tpr'],1./genDictScoreObs[i]['fpr'], label=lab+f' (AUC={genDictScoreObs[i][\"AUC\"]})',\n",
    "             ls='--', lw=2)\n",
    "    \n",
    "hep.cms.label(rlabel=r\"Boosted $W$ vs. QCD, 13 TeV\")\n",
    "ax.legend(title='Hadron-level',ncols=1,fontsize=16,title_fontsize=18)\n",
    "ax.set_xlabel('Signal efficiency', loc='center')\n",
    "ax.set_ylabel('QCD rejection rate', loc='center')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.ylim(0.8,700)\n",
    "plt.xlim(0,1.0)\n",
    "fig.savefig('../Plots/SaturationROC_gen_WvsQCD.pdf', dpi=1200)\n",
    "fig.savefig('../Plots/SaturationROC_gen_WvsQCD.png', dpi=1200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f415a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,9))\n",
    "\n",
    "#reco level\n",
    "for i in recoDictScoreNN.keys():\n",
    "    plt.plot(recoDictScoreNN[i]['tpr'],1./recoDictScoreNN[i]['fpr'], label=i.split('_DNN')[0]+f' DNN (AUC={recoDictScoreNN[i][\"AUC\"]})',\n",
    "             ls='-', lw=2)\n",
    "for i in recoDictScoreObs.keys():\n",
    "    print(i)\n",
    "    if 'ex' in i: lab=r'$\\%s_{21}^{%s}$'%(i.split('21')[0],r'excl.\\ k_{T}')\n",
    "    elif 'WTA' in i: lab=r'$\\%s_{21}^{%s}$'%(i.split('21')[0],r'WTA\\ k_{T}')\n",
    "    elif i=='tau21_WvsQCD': lab=r'$\\%s_{21}^{%s}$'%(i.split('21')[0],r'OP\\ k_{T}' )\n",
    "    plt.plot(recoDictScoreObs[i]['tpr'],1./recoDictScoreObs[i]['fpr'], label=lab+f' (AUC={recoDictScoreObs[i][\"AUC\"]})',\n",
    "             ls='--', lw=2)\n",
    "    \n",
    "hep.cms.label(rlabel=r\"Boosted $W$ vs. QCD, 13 TeV\")\n",
    "ax.legend(title='Detector-level',ncols=1,fontsize=16,title_fontsize=18)\n",
    "ax.set_xlabel('Signal efficiency', loc='center')\n",
    "ax.set_ylabel('QCD rejection rate', loc='center')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.ylim(0.8,700)\n",
    "plt.xlim(0,1.0)\n",
    "fig.savefig('../Plots/SaturationROC_reco_WvsQCD.pdf', dpi=1200)\n",
    "fig.savefig('../Plots/SaturationROC_reco_WvsQCD.png', dpi=1200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6c6c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb950a01",
   "metadata": {},
   "source": [
    "## top vs QCD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893c3403",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c3e62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpDir='../data/'\n",
    "cols=dict()\n",
    "hidden_size1=500\n",
    "hidden_size2=250\n",
    "hidden_size3=100\n",
    "hidden_size4=50\n",
    "batch_size = 5000\n",
    "epochs = 400\n",
    "cmap = get_cmap(30)\n",
    "\n",
    "#branch ordering\n",
    "#0'selGenJets_nom_pt', 1'selGenJets_nom_msoftdrop',  \n",
    "#2'selGenJets_nom_tau_0p5_1', 3'selGenJets_nom_tau_1_1', 4'selGenJets_nom_tau_2_1',\n",
    "#5'selGenJets_nom_tau_0p5_2', 6'selGenJets_nom_tau_1_2', 7'selGenJets_nom_tau_2_2',\n",
    "#8'selGenJets_nom_tau_0p5_3', 9'selGenJets_nom_tau_1_3', 10'selGenJets_nom_tau_2_3',\n",
    "#11'selGenJets_nom_tau_0p5_4', 12'selGenJets_nom_tau_1_4', 13'selGenJets_nom_tau_2_4', \n",
    "#14'selGenJets_nom_tau_0p5_5', 15'selGenJets_nom_tau_1_5', 16'selGenJets_nom_tau_2_5',\n",
    "#17'selGenJets_nom_tau21', 18'selGenJets_nom_tau32', \n",
    "#19'selGenJets_nom_tau21_WTA',20'selGenJets_nom_tau32_WTA', \n",
    "#21'selGenJets_nom_tau21_exkT',22'selGenJets_nom_tau32_exkT', \n",
    "cols['2-body'] = [3,4]\n",
    "cols['3-body'] = [2,3,4,6,7]\n",
    "cols['4-body'] = [2,3,4,5,6,7,9,10]\n",
    "cols['5-body'] = [2,3,4,5,6,7,8,9,10,12,13]\n",
    "cols['6-body'] = [2,3,4,5,6,7,8,9,10,11,12,13,15,16]\n",
    "cols['tau21'] = [17]\n",
    "cols['tau32'] = [18]\n",
    "cols['tau21_WTA'] = [19]\n",
    "cols['tau32_WTA'] = [20]\n",
    "cols['tau21_exkT'] = [21]\n",
    "cols['tau32_exkT'] = [22]\n",
    "\n",
    "Ms = [2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecd3158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from collections import OrderedDict\n",
    "genDictScoreNN = OrderedDict()\n",
    "genDictScoreObs = OrderedDict()\n",
    "recoDictScoreNN = OrderedDict()\n",
    "recoDictScoreObs = OrderedDict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c379a0c2",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ea0911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "for sampleType in ['toplike']:\n",
    "    for genORreco in ['gen','reco']:#,'reco']\n",
    "        print(sampleType,genORreco)\n",
    "        for f in os.listdir(inpDir):\n",
    "\n",
    "            if not(sampleType in f and genORreco in f): continue\n",
    "            print (f,genORreco)\n",
    "            file = h5py.File(inpDir+f,'r')\n",
    "\n",
    "            inputs = np.array(file['inputs']).reshape(file['inputs'].shape[1],file['inputs'].shape[2])\n",
    "            targets = np.array(file['target']).flatten()#reshape(targets.shape[1])\n",
    "            #print(inputs.shape[0],targets[0:100])\n",
    "            dataset_dict = split_data(inputs,targets)\n",
    "            file.close()\n",
    "        \n",
    "        print(f\"Train set shape: Inputs {dataset_dict['inputs']['train'].shape}, Target {dataset_dict['targets']['train'].shape}\")\n",
    "        print(f\"Validate set shape: Inputs {dataset_dict['inputs']['validate'].shape}, Target {dataset_dict['targets']['validate'].shape}\")\n",
    "        print(f\"Test set shape: Inputs {dataset_dict['inputs']['test'].shape}, Target {dataset_dict['targets']['test'].shape}\")\n",
    "\n",
    "        ### M-body DNN training for W/top vs. QCD ###\n",
    "        inputs_train = dataset_dict['inputs']['train']\n",
    "        inputs_val = dataset_dict['inputs']['validate']\n",
    "        inputs_test = dataset_dict['inputs']['test']\n",
    "        target_train = dataset_dict['targets']['train']\n",
    "        target_val = dataset_dict['targets']['validate']\n",
    "        target_test = dataset_dict['targets']['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1d698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sampleType in ['toplike']:#,'toplike']:\n",
    "    for genORreco in ['gen','reco']:#,'reco']\n",
    "        print(sampleType,genORreco)\n",
    "        \n",
    "        score=[0,0]\n",
    "\n",
    "        for M in Ms:\n",
    "            plt.figure(figsize=(12, 9))\n",
    "\n",
    "            input_shape=(len(cols[f'{M}-body']),)\n",
    "            for i in range(1,10):\n",
    "                DNN_topvsQCD_Mbody = keras.Sequential([\n",
    "                        layers.Dense(hidden_size1, activation='relu', input_shape=input_shape),\n",
    "                        layers.Dropout(0.2),\n",
    "                        layers.Dense(hidden_size2, activation='relu'),\n",
    "                        layers.Dropout(0.2),\n",
    "                        layers.Dense(hidden_size3, activation='relu'),\n",
    "                        layers.Dropout(0.1),\n",
    "                        layers.Dense(hidden_size4, activation='relu'),\n",
    "                        layers.Dropout(0.1),\n",
    "                        layers.Dense(1, activation='sigmoid')\n",
    "                    ])\n",
    "                DNN_topvsQCD_Mbody.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "                #DNN_topvsQCD_Mbody.summary()\n",
    "                modelname = f\"{genORreco}_DNN_topvsQCD_{M}body_{i}\"   \n",
    "                #print (f\"Training {modelname}\")\n",
    "                check = keras.callbacks.ModelCheckpoint(filepath=f\"../saved_weightsAndES/{modelname}_check.h5\", verbose=0)\n",
    "                early = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto')\n",
    "                history = DNN_topvsQCD_Mbody.fit(  \n",
    "                                                inputs_train[:,cols[f'{M}-body']], target_train, \n",
    "                                                batch_size=batch_size, epochs=epochs, \n",
    "                                                steps_per_epoch=5,\n",
    "                                                validation_data=(inputs_val[:,cols[f'{M}-body']], target_val),\n",
    "                                                validation_batch_size=int(batch_size/2), validation_steps=4, \n",
    "                                                verbose=0, callbacks=[check, early]\n",
    "                                               )\n",
    "                savelosses(history,outDir='../saved_weightsAndES/',name=modelname)\n",
    "                savemodel(DNN_topvsQCD_Mbody,outDir='../models/',name=modelname)\n",
    "\n",
    "                plt.plot(history.history['loss'], color=cmap(i), label=(f\"{i}_loss\"))\n",
    "                plt.plot(history.history['val_loss'], linestyle=\"--\", color=cmap(i))    \n",
    "\n",
    "                pred = DNN_topvsQCD_Mbody.predict([inputs_test[:,cols[f'{M}-body']]])\n",
    "                fpr,tpr,_ = roc_curve(target_test,pred)\n",
    "                ls = ['-' , '--' , '-.']\n",
    "                area = auc(fpr, tpr)\n",
    "                if area>score[0]:\n",
    "                    score[0]=area\n",
    "                    score[1]=i\n",
    "                if area<=0.6:\n",
    "                    continue\n",
    "                l = 'Training %d, auc=%f'%(i,area)\n",
    "                print(l,modelname,score)\n",
    "                del(DNN_topvsQCD_Mbody)\n",
    "                gc.collect()\n",
    "\n",
    "            #plt.yscale('log')\n",
    "            plt.xlabel('Epoch', fontsize = 20)\n",
    "            plt.ylabel('Loss', fontsize = 20)\n",
    "            plt.title('Training Error by Epoch', fontsize = 20)    \n",
    "            plt.legend(loc='best', fontsize = 15, fancybox=True, framealpha=0.0)\n",
    "            plt.rc('xtick', labelsize = 16)\n",
    "            plt.rc('ytick', labelsize = 16)   \n",
    "            plt.savefig(f\"../Plots/{genORreco}_DNN_topvsQCD_{M}body_losses.pdf\")\n",
    "            plt.savefig(f\"../Plots/{genORreco}_DNN_topvsQCD_{M}body_losses.png\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed8dca3",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3168dbe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "genDictScoreNN=dict()\n",
    "recoDictScoreNN=dict()\n",
    "genDictScoreObs=dict()\n",
    "recoDictScoreObs=dict()\n",
    "gc.collect()\n",
    "\n",
    "problem = ['topvsQCD']\n",
    "for p in problem:#,'toplike']:\n",
    "    for genORreco in ['gen','reco']:\n",
    "        for obs in cols.keys():\n",
    "            if not('tau' in obs):\n",
    "                genDictScoreNN[f'{obs}_DNN_{p}']=dict()\n",
    "                recoDictScoreNN[f'{obs}_DNN_{p}']=dict()\n",
    "            else:  \n",
    "                if('32' in obs and 'W' in p): continue \n",
    "                if('21' in obs and 'top' in p): continue \n",
    "                genDictScoreObs[f'{obs}_{p}']=dict()\n",
    "                recoDictScoreObs[f'{obs}_{p}']=dict()\n",
    "            print(p,genORreco,obs)\n",
    "\n",
    "print(genDictScoreNN,recoDictScoreNN,genDictScoreObs,recoDictScoreObs)\n",
    "\n",
    "for p in problem:#,'toplike']:\n",
    "    for genORreco in ['gen','reco']:\n",
    "        for obs in cols.keys():\n",
    "            print(obs,genORreco,p)\n",
    "            #print(sampleType,genORreco)\n",
    "            \n",
    "            if not('tau' in obs):\n",
    "                \n",
    "                best_score=[0,0]\n",
    "                for i in range(1,10):\n",
    "                    \n",
    "                    modelname=f'{genORreco}_DNN_{p}_{obs.split(\"-\")[0]}body_{i}'\n",
    "                    model = loadmodel(modelname,inDir='../models/')\n",
    "                    prediction = np.array(model.predict(np.array(inputs_test[:,cols[obs]]),verbose=0))\n",
    "                    fpr, tpr, _ = roc_curve(np.array(target_test),prediction)\n",
    "                    area = auc(fpr,tpr)\n",
    "                    \n",
    "                    if area>best_score[0]:\n",
    "                        \n",
    "                        best_score[0]=area\n",
    "                        best_score[1]=i\n",
    "                        if 'gen' in genORreco:\n",
    "                            genDictScoreNN[f'{obs}_DNN_{p}']['fpr'] = fpr\n",
    "                            genDictScoreNN[f'{obs}_DNN_{p}']['tpr'] = tpr\n",
    "                            genDictScoreNN[f'{obs}_DNN_{p}'][\"AUC\"] = np.round(area,3)\n",
    "                            genDictScoreNN[f'{obs}_DNN_{p}']['model'] = modelname\n",
    "                        elif 'reco' in genORreco:\n",
    "                            recoDictScoreNN[f'{obs}_DNN_{p}']['fpr'] = fpr\n",
    "                            recoDictScoreNN[f'{obs}_DNN_{p}']['tpr'] = tpr\n",
    "                            recoDictScoreNN[f'{obs}_DNN_{p}'][\"AUC\"] = np.round(area,3)\n",
    "                            recoDictScoreNN[f'{obs}_DNN_{p}']['model'] = modelname\n",
    "                            \n",
    "                        #print(obs,modelname,genDictScoreNN,recoDictScoreNN)\n",
    "\n",
    "                    elif area<=0.6:\n",
    "                        continue\n",
    "            elif ('tau' in obs):\n",
    "                if('32' in obs and 'W' in p): continue \n",
    "                if('21' in obs and 'top' in p): continue \n",
    "                \n",
    "                inds_0 = np.where(target_test==0)\n",
    "                inds_1 = np.where(target_test==1)\n",
    "                print (len(inds_0),len(inds_1))\n",
    "                fpr,tpr,area = makeROC_obs(sig=inputs_test[:,cols[obs]][inds_1],\n",
    "                                           bkg=inputs_test[:,cols[obs]][inds_0])\n",
    "                if 'gen' in genORreco:\n",
    "                    genDictScoreObs[f'{obs}_{p}']['fpr'] = fpr\n",
    "                    genDictScoreObs[f'{obs}_{p}']['tpr'] = tpr\n",
    "                    genDictScoreObs[f'{obs}_{p}'][\"AUC\"] = np.round(area,3)\n",
    "                elif 'reco' in genORreco:\n",
    "                    recoDictScoreObs[f'{obs}_{p}']['fpr'] = fpr\n",
    "                    recoDictScoreObs[f'{obs}_{p}']['tpr'] = tpr\n",
    "                    recoDictScoreObs[f'{obs}_{p}'][\"AUC\"] = np.round(area,3)\n",
    "                    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e93bc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(genDictScoreNN)\n",
    "print(genDictScoreObs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9041abdc",
   "metadata": {},
   "source": [
    "### Make saturation ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9abeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mplhep as hep\n",
    "import matplotlib.pyplot as plt\n",
    "hep.style.use(\"CMS\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5cb405",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,9))\n",
    "\n",
    "#gen level\n",
    "for i in genDictScoreNN.keys():\n",
    "    plt.plot(genDictScoreNN[i]['tpr'],1./genDictScoreNN[i]['fpr'], label=i.split('_DNN')[0]+f' DNN (AUC={genDictScoreNN[i][\"AUC\"]})',\n",
    "             ls='-', lw=2)\n",
    "for i in genDictScoreObs.keys():\n",
    "    print(i)\n",
    "    if 'ex' in i: lab=r'$\\%s_{32}^{%s}$'%(i.split('32')[0],r'excl.\\ k_{T}')\n",
    "    elif 'WTA' in i: lab=r'$\\%s_{32}^{%s}$'%(i.split('32')[0],r'WTA\\ k_{T}')\n",
    "    elif i=='tau32_topvsQCD': lab=r'$\\%s_{32}^{%s}$'%(i.split('32')[0],r'OP\\ k_{T}' )\n",
    "    plt.plot(genDictScoreObs[i]['tpr'],1./genDictScoreObs[i]['fpr'], label=lab+f' (AUC={genDictScoreObs[i][\"AUC\"]})',\n",
    "             ls='--', lw=2)\n",
    "    \n",
    "hep.cms.label(rlabel=r\"Boosted $top$ vs. QCD, 13 TeV\")\n",
    "ax.legend(title='Hadron-level',ncols=1,fontsize=16,title_fontsize=18)\n",
    "ax.set_xlabel('Signal efficiency', loc='center')\n",
    "ax.set_ylabel('QCD rejection rate', loc='center')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.ylim(0.8,700)\n",
    "plt.xlim(0,1.0)\n",
    "fig.savefig('../Plots/SaturationROC_gen_topvsQCD.pdf', dpi=1200)\n",
    "fig.savefig('../Plots/SaturationROC_gen_topvsQCD.png', dpi=1200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e6b9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,9))\n",
    "\n",
    "#reco level\n",
    "for i in recoDictScoreNN.keys():\n",
    "    plt.plot(recoDictScoreNN[i]['tpr'],1./recoDictScoreNN[i]['fpr'], label=i.split('_DNN')[0]+f' DNN (AUC={recoDictScoreNN[i][\"AUC\"]})',\n",
    "             ls='-', lw=2)\n",
    "for i in recoDictScoreObs.keys():\n",
    "    print(i)\n",
    "    if 'ex' in i: lab=r'$\\%s_{32}^{%s}$'%(i.split('32')[0],r'excl.\\ k_{T}')\n",
    "    elif 'WTA' in i: lab=r'$\\%s_{32}^{%s}$'%(i.split('32')[0],r'WTA\\ k_{T}')\n",
    "    elif i=='tau32_topvsQCD': lab=r'$\\%s_{32}^{%s}$'%(i.split('32')[0],r'OP\\ k_{T}' )\n",
    "    plt.plot(recoDictScoreObs[i]['tpr'],1./recoDictScoreObs[i]['fpr'], label=lab+f' (AUC={recoDictScoreObs[i][\"AUC\"]})',\n",
    "             ls='--', lw=2)\n",
    "    \n",
    "hep.cms.label(rlabel=r\"Boosted $top$ vs. QCD, 13 TeV\")\n",
    "ax.legend(title='Detector-level',ncols=1,fontsize=16,title_fontsize=18)\n",
    "ax.set_xlabel('Signal efficiency', loc='center')\n",
    "ax.set_ylabel('QCD rejection rate', loc='center')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.ylim(0.8,700)\n",
    "plt.xlim(0,1.0)\n",
    "fig.savefig('../Plots/SaturationROC_reco_topvsQCD.pdf', dpi=1200)\n",
    "fig.savefig('../Plots/SaturationROC_reco_topvsQCD.png', dpi=1200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e81b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107b0b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdf9630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68cede9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
